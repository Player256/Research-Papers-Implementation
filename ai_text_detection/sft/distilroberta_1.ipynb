{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7914522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raid.utils import load_data\n",
    "\n",
    "train_df = load_data(split=\"train\",include_adversarial=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f56d0f",
   "metadata": {},
   "source": [
    "Human model will have NaN decoding duh!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f8475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_df['model'] = np.where(train_df['model'] == 'human',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d189e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "1    454614\n",
       "0     13371\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb687be",
   "metadata": {},
   "source": [
    "The class imbalance for Ai vs Human is 35:1. So to combat this we have to use class weighting. Adding this weight = (total number of samples)/(number of classes * number of samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "107f4fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>adv_source_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>model</th>\n",
       "      <th>decoding</th>\n",
       "      <th>repetition_penalty</th>\n",
       "      <th>attack</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>EdgeFlow: Achieving Practical Interactive Segm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High-quality training data play a key role in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Semi-supervised Contrastive Learning for Label...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The success of deep learning methods in medica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Combo Loss: Handling Input and Output Imbalanc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Simultaneous segmentation of multiple organs f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Attention-Based 3D Seismic Fault Segmentation ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Detection faults in seismic data is a crucial ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                         adv_source_id  \\\n",
       "0  e5e058ce-be2b-459d-af36-32532aaba5ff  e5e058ce-be2b-459d-af36-32532aaba5ff   \n",
       "1  f95b107b-d176-4af5-90f7-4d0bb20caf93  f95b107b-d176-4af5-90f7-4d0bb20caf93   \n",
       "2  856d8972-9e3d-4544-babc-0fe16f21e04d  856d8972-9e3d-4544-babc-0fe16f21e04d   \n",
       "3  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524   \n",
       "4  72c41b8d-0069-4886-b734-a4000ffca286  72c41b8d-0069-4886-b734-a4000ffca286   \n",
       "\n",
       "                              source_id  model decoding repetition_penalty  \\\n",
       "0  e5e058ce-be2b-459d-af36-32532aaba5ff      0      NaN                NaN   \n",
       "1  f95b107b-d176-4af5-90f7-4d0bb20caf93      0      NaN                NaN   \n",
       "2  856d8972-9e3d-4544-babc-0fe16f21e04d      0      NaN                NaN   \n",
       "3  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524      0      NaN                NaN   \n",
       "4  72c41b8d-0069-4886-b734-a4000ffca286      0      NaN                NaN   \n",
       "\n",
       "  attack     domain                                              title prompt  \\\n",
       "0   none  abstracts  FUTURE-AI: Guiding Principles and Consensus Re...    NaN   \n",
       "1   none  abstracts  EdgeFlow: Achieving Practical Interactive Segm...    NaN   \n",
       "2   none  abstracts  Semi-supervised Contrastive Learning for Label...    NaN   \n",
       "3   none  abstracts  Combo Loss: Handling Input and Output Imbalanc...    NaN   \n",
       "4   none  abstracts  Attention-Based 3D Seismic Fault Segmentation ...    NaN   \n",
       "\n",
       "                                          generation  \n",
       "0  The recent advancements in artificial intellig...  \n",
       "1  High-quality training data play a key role in ...  \n",
       "2  The success of deep learning methods in medica...  \n",
       "3  Simultaneous segmentation of multiple organs f...  \n",
       "4  Detection faults in seismic data is a crucial ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ee0343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>adv_source_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>decoding</th>\n",
       "      <th>repetition_penalty</th>\n",
       "      <th>attack</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>EdgeFlow: Achieving Practical Interactive Segm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High-quality training data play a key role in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Semi-supervised Contrastive Learning for Label...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The success of deep learning methods in medica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Combo Loss: Handling Input and Output Imbalanc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Simultaneous segmentation of multiple organs f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Attention-Based 3D Seismic Fault Segmentation ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Detection faults in seismic data is a crucial ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                         adv_source_id  \\\n",
       "0  e5e058ce-be2b-459d-af36-32532aaba5ff  e5e058ce-be2b-459d-af36-32532aaba5ff   \n",
       "1  f95b107b-d176-4af5-90f7-4d0bb20caf93  f95b107b-d176-4af5-90f7-4d0bb20caf93   \n",
       "2  856d8972-9e3d-4544-babc-0fe16f21e04d  856d8972-9e3d-4544-babc-0fe16f21e04d   \n",
       "3  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524   \n",
       "4  72c41b8d-0069-4886-b734-a4000ffca286  72c41b8d-0069-4886-b734-a4000ffca286   \n",
       "\n",
       "                              source_id  labels decoding repetition_penalty  \\\n",
       "0  e5e058ce-be2b-459d-af36-32532aaba5ff       0      NaN                NaN   \n",
       "1  f95b107b-d176-4af5-90f7-4d0bb20caf93       0      NaN                NaN   \n",
       "2  856d8972-9e3d-4544-babc-0fe16f21e04d       0      NaN                NaN   \n",
       "3  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524       0      NaN                NaN   \n",
       "4  72c41b8d-0069-4886-b734-a4000ffca286       0      NaN                NaN   \n",
       "\n",
       "  attack     domain                                              title prompt  \\\n",
       "0   none  abstracts  FUTURE-AI: Guiding Principles and Consensus Re...    NaN   \n",
       "1   none  abstracts  EdgeFlow: Achieving Practical Interactive Segm...    NaN   \n",
       "2   none  abstracts  Semi-supervised Contrastive Learning for Label...    NaN   \n",
       "3   none  abstracts  Combo Loss: Handling Input and Output Imbalanc...    NaN   \n",
       "4   none  abstracts  Attention-Based 3D Seismic Fault Segmentation ...    NaN   \n",
       "\n",
       "                                             content  \n",
       "0  The recent advancements in artificial intellig...  \n",
       "1  High-quality training data play a key role in ...  \n",
       "2  The success of deep learning methods in medica...  \n",
       "3  Simultaneous segmentation of multiple organs f...  \n",
       "4  Detection faults in seismic data is a crucial ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df = train_df.drop(\n",
    "#     [\n",
    "#         \"id\",\n",
    "#         \"decoding\",\n",
    "#         \"domain\",\n",
    "#         \"adv_source_id\",\n",
    "#         \"source_id\",\n",
    "#         \"repetition_penalty\",\n",
    "#         \"attack\",\n",
    "#         \"title\",\n",
    "#         \"prompt\"\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )\n",
    "\n",
    "train_df = train_df.rename(columns={\n",
    "    \"generation\" : \"content\",\n",
    "    \"model\" : \"labels\"\n",
    "})\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3a35f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.5         0.51470588]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "labels = train_df[\"labels\"]\n",
    "\n",
    "class_weights = compute_class_weight(\"balanced\",classes=np.unique(labels),y=labels)\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9336348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "model_path = \"distilbert/distilroberta-base\"\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights).to(\"cuda\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path,num_labels=2).to(\"cuda\")\n",
    "tokeinzer = AutoTokenizer.from_pretrained(model_path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74d96935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "train_data, val_data = train_test_split(train_df, test_size=0.1, random_state=42, stratify=train_df[\"labels\"])\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "\n",
    "val_data,test_data = train_test_split(val_data, test_size=0.5, random_state=42, stratify=val_data[\"labels\"])\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "180fbe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'adv_source_id', 'source_id', 'labels', 'decoding', 'repetition_penalty', 'attack', 'domain', 'title', 'prompt', 'content'],\n",
       "    num_rows: 421186\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46cd38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.remove_columns([\"__index_level_0__\"])\n",
    "val_dataset = val_dataset.remove_columns([\"__index_level_0__\"])\n",
    "test_dataset = test_dataset.remove_columns([\"__index_level_0__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aee500c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f00bd0d08f4c7fa25f87408a7e8080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_fn(batch):\n",
    "    encodings = tokenizer(\n",
    "        batch[\"content\"], truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\"\n",
    "    )\n",
    "    return encodings\n",
    "\n",
    "\n",
    "# train_dataset = train_dataset.map(preprocess_fn, batched=True)\n",
    "# val_dataset = val_dataset.map(preprocess_fn, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f622f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'adv_source_id', 'source_id', 'labels', 'decoding', 'repetition_penalty', 'attack', 'domain', 'title', 'prompt', 'content', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 23400\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "957de756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22631/3357938601.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False,**kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=3e-5,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"distilroberta-noadv-raid\"\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokeinzer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db248083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdattucodes\u001b[0m (\u001b[33mdeath-star\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/oracle/Research-Papers-Implementation/ai_text_detection/sft/wandb/run-20250912_101124-r1itdq9q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/death-star/huggingface/runs/r1itdq9q' target=\"_blank\">distilroberta-noadv-raid</a></strong> to <a href='https://wandb.ai/death-star/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/death-star/huggingface' target=\"_blank\">https://wandb.ai/death-star/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/death-star/huggingface/runs/r1itdq9q' target=\"_blank\">https://wandb.ai/death-star/huggingface/runs/r1itdq9q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26326' max='26325' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26325/26325 2:29:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.122351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"The `metric_for_best_model` training argument is set to 'eval_f1', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_loss']. Consider changing the `metric_for_best_model` via the TrainingArguments.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/idm/lib/python3.10/site-packages/transformers/trainer.py:3296\u001b[0m, in \u001b[0;36mTrainer._determine_best_metric\u001b[0;34m(self, metrics, trial)\u001b[0m\n\u001b[1;32m   3295\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3296\u001b[0m     metric_value \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_to_check\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   3297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'eval_f1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/idm/lib/python3.10/site-packages/transformers/trainer.py:2328\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2326\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/idm/lib/python3.10/site-packages/transformers/trainer.py:2788\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2787\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2788\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\n\u001b[1;32m   2790\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2794\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/idm/lib/python3.10/site-packages/transformers/trainer.py:3228\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[1;32m   3227\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[0;32m-> 3228\u001b[0m     is_new_best_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_determine_best_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST:\n\u001b[1;32m   3231\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save \u001b[38;5;241m=\u001b[39m is_new_best_metric\n",
      "File \u001b[0;32m/opt/conda/envs/idm/lib/python3.10/site-packages/transformers/trainer.py:3298\u001b[0m, in \u001b[0;36mTrainer._determine_best_metric\u001b[0;34m(self, metrics, trial)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     metric_value \u001b[38;5;241m=\u001b[39m metrics[metric_to_check]\n\u001b[1;32m   3297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 3298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   3299\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `metric_for_best_model` training argument is set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_to_check\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, which is not found in the evaluation metrics. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3300\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe available evaluation metrics are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider changing the `metric_for_best_model` via the TrainingArguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3301\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m   3303\u001b[0m operator \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgreater \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgreater_is_better \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mless\n\u001b[1;32m   3305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_metric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The `metric_for_best_model` training argument is set to 'eval_f1', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_loss']. Consider changing the `metric_for_best_model` via the TrainingArguments.\""
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "612bfb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_path = \"./distilroberta-noadv-raid\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path,num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd19383a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23400/23400 [11:26<00:00, 34.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def inference(texts) -> list:\n",
    "    predictions = []\n",
    "    for text in tqdm(texts):\n",
    "        inputs = tokenizer(text[\"content\"], truncation=True, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)  \n",
    "        probs = outputs.logits.softmax(dim=-1)\n",
    "        _, fake = probs.detach().cpu().flatten().numpy().tolist()\n",
    "        predictions.append({\n",
    "            'id' : text['id'],\n",
    "            'score' : fake\n",
    "        })\n",
    "    return predictions\n",
    "\n",
    "\n",
    "preds = inference(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe42f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Predictions are missing outputs for human-written texts in some domains.\nIn order to run evaluation, you must include predictions for human-written data in all domains.\nTo disable this, set per_domain_tuning=False in run_evaluation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m test_df \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[1;32m      5\u001b[0m test_df \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39mrename(\n\u001b[1;32m      6\u001b[0m     columns\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m     }\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m result\n",
      "File \u001b[0;32m/opt/conda/envs/idm/lib/python3.10/site-packages/raid/evaluate.py:236\u001b[0m, in \u001b[0;36mrun_evaluation\u001b[0;34m(results, df, target_fpr, epsilon, per_domain_tuning, require_complete, include_all)\u001b[0m\n\u001b[1;32m    233\u001b[0m df \u001b[38;5;241m=\u001b[39m load_detection_result(df, results)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Find thresholds per-domain for target FPR\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m thresholds, fprs \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_thresholds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_fpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_domain_tuning\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Compute accuracy scores for each split of the data\u001b[39;00m\n\u001b[1;32m    239\u001b[0m scores \u001b[38;5;241m=\u001b[39m compute_scores(df, thresholds, require_complete)\n",
      "File \u001b[0;32m/opt/conda/envs/idm/lib/python3.10/site-packages/raid/evaluate.py:95\u001b[0m, in \u001b[0;36mcompute_thresholds\u001b[0;34m(df, fpr, epsilon, per_domain_tuning)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m---> 95\u001b[0m         t, true_fpr \u001b[38;5;241m=\u001b[39m \u001b[43mfind_threshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdomain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpr_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m         thresholds[\u001b[38;5;28mstr\u001b[39m(fpr_value)][d] \u001b[38;5;241m=\u001b[39m t\n\u001b[1;32m     97\u001b[0m         true_fprs[\u001b[38;5;28mstr\u001b[39m(fpr_value)][d] \u001b[38;5;241m=\u001b[39m true_fpr\n",
      "File \u001b[0;32m/opt/conda/envs/idm/lib/python3.10/site-packages/raid/evaluate.py:38\u001b[0m, in \u001b[0;36mfind_threshold\u001b[0;34m(df, target_fpr, epsilon)\u001b[0m\n\u001b[1;32m     36\u001b[0m     threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(y_scores) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_scores)  \u001b[38;5;66;03m# initialize threshold to mean of y_scores\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions are missing outputs for human-written texts in some domains.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to run evaluation, you must include predictions for human-written data in all domains.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo disable this, set per_domain_tuning=False in run_evaluation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Initialize the list of all found thresholds and FPRs\u001b[39;00m\n\u001b[1;32m     45\u001b[0m found_threshold_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: Predictions are missing outputs for human-written texts in some domains.\nIn order to run evaluation, you must include predictions for human-written data in all domains.\nTo disable this, set per_domain_tuning=False in run_evaluation."
     ]
    }
   ],
   "source": [
    "from raid import run_evaluation\n",
    "\n",
    "test_df = test_dataset.to_pandas()\n",
    "\n",
    "result = run_evaluation(preds, test_df)\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
