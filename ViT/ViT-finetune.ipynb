{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms  \n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO,Evaluator\n",
    "\n",
    "from transformers import ViTConfig, ViTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_paths = [\n",
    "    \"pathmnist\",\n",
    "    \"bloodmnist\",\n",
    "    \"breastmnist\",\n",
    "    \"dermamnist\",\n",
    "    \"octmnist\",\n",
    "    \"organamnist\",\n",
    "    \"organcmnist\",\n",
    "    \"organsmnist\",\n",
    "    \"pneumoniamnist\",\n",
    "    \"retinamnist\",\n",
    "    \"tissuemnist\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_flag = 'pathmnist'\n",
    "DOWNLOAD = True\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(\n",
    "    model, num_epochs, optimizer, loss_function, trainloader, validloader, device\n",
    "):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        progress_bar = tqdm(\n",
    "            trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False\n",
    "        )\n",
    "        for inputs, targets in progress_bar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device).squeeze()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            pooled_output = outputs.pooler_output\n",
    "            logits = model.classifier(pooled_output)\n",
    "            loss = loss_function(logits, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = logits.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            progress_bar.set_postfix(\n",
    "                {\n",
    "                    \"loss\": f\"{train_loss / len(trainloader):.4f}\",\n",
    "                    \"acc\": f\"{100. * correct / total:.2f}%\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "        train_accuracy = 100.0 * correct / total\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss/len(trainloader):.4f}, Train Accuracy: {train_accuracy:.2f}%\"\n",
    "        )\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in validloader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device).squeeze()\n",
    "                outputs = model(inputs)\n",
    "                pooled_output = outputs.pooler_output\n",
    "                logits = model.classifier(pooled_output)\n",
    "                loss = loss_function(logits, targets)\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "                _, predicted = logits.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        valid_accuracy = 100.0 * correct / total\n",
    "        print(\n",
    "            f\"Validation Loss: {valid_loss/len(validloader):.4f}, Validation Accuracy: {valid_accuracy:.2f}%\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiheaded_vit(data_flag):\n",
    "\n",
    "    ##Load the dataset\n",
    "    info = INFO[data_flag]\n",
    "    task = info[\"task\"]\n",
    "    n_channels = info[\"n_channels\"]\n",
    "    n_classes = len(info[\"label\"])\n",
    "\n",
    "    DataClass = getattr(medmnist, info[\"python_class\"])\n",
    "\n",
    "    ## Data Augmentation\n",
    "    train_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    test_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ##Data Loaders\n",
    "    train_dataset = DataClass(\n",
    "        split=\"train\", transform=train_transform, download=DOWNLOAD\n",
    "    )\n",
    "    test_dataset = DataClass(split=\"test\", transform=test_transform, download=DOWNLOAD)\n",
    "    val_dataset = DataClass(split=\"val\", transform=test_transform, download=DOWNLOAD)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    ## Load the model\n",
    "    config = ViTConfig.from_pretrained(\n",
    "        \"google/vit-base-patch16-224-in21k\",\n",
    "        num_labels=n_classes,\n",
    "        image_size=224,\n",
    "        num_channels=n_channels,    \n",
    "    )\n",
    "    model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\", config=config)\n",
    "    model.classifier = nn.Linear(model.config.hidden_size, n_classes)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    ## Change the id2label and label2id\n",
    "    model.config.id2label = {i: label for i, label in enumerate(info[\"label\"].values())}\n",
    "    model.config.label2id = {label: i for i, label in enumerate(info[\"label\"].values())}\n",
    "\n",
    "    ## Loss and Optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    ##Train Loop\n",
    "    train_network(\n",
    "        model, NUM_EPOCHS, optimizer, criterion, train_loader, val_loader, DEVICE\n",
    "    )\n",
    "\n",
    "    ##Save Model\n",
    "    torch.save(model.state_dict(), f\"{data_flag}_vit.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on pathmnist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/ubuntu/.medmnist/pathmnist.npz\n",
      "Using downloaded and verified file: /home/ubuntu/.medmnist/pathmnist.npz\n",
      "Using downloaded and verified file: /home/ubuntu/.medmnist/pathmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss: 0.5568, Train Accuracy: 79.55%\n",
      "Validation Loss: 0.2922, Validation Accuracy: 89.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: Train Loss: 0.2604, Train Accuracy: 90.90%\n",
      "Validation Loss: 0.1889, Validation Accuracy: 93.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: Train Loss: 0.1991, Train Accuracy: 93.19%\n",
      "Validation Loss: 0.1536, Validation Accuracy: 95.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: Train Loss: 0.1621, Train Accuracy: 94.42%\n",
      "Validation Loss: 0.1726, Validation Accuracy: 94.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: Train Loss: 0.1378, Train Accuracy: 95.31%\n",
      "Validation Loss: 0.1282, Validation Accuracy: 95.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: Train Loss: 0.1173, Train Accuracy: 96.01%\n",
      "Validation Loss: 0.1206, Validation Accuracy: 95.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: Train Loss: 0.1058, Train Accuracy: 96.39%\n",
      "Validation Loss: 0.1248, Validation Accuracy: 95.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_flag \u001b[38;5;129;01min\u001b[39;00m datasets_paths:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_flag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mmultiheaded_vit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_flag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_flag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[41], line 63\u001b[0m, in \u001b[0;36mmultiheaded_vit\u001b[0;34m(data_flag)\u001b[0m\n\u001b[1;32m     60\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m##Train Loop\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m##Save Model\u001b[39;00m\n\u001b[1;32m     68\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_flag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_vit.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 26\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(model, num_epochs, optimizer, loss_function, trainloader, validloader, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 26\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if 'DOWNLOAD' not in globals():\n",
    "    DOWNLOAD = True\n",
    "\n",
    "for data_flag in datasets_paths:\n",
    "    print(f\"Training on {data_flag}\")\n",
    "    multiheaded_vit(data_flag)\n",
    "    print(f\"Training on {data_flag} completed\")\n",
    "    print(\"---------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
