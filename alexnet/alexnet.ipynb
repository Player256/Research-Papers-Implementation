{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "# Normalization for testing\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(192, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 4 * 4, 4096),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc3 = nn.Linear(4096, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fc3): Linear(in_features=4096, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ke684kew) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-terrain-9</strong> at: <a href='https://wandb.ai/death-star/image-classification/runs/ke684kew' target=\"_blank\">https://wandb.ai/death-star/image-classification/runs/ke684kew</a><br/> View project at: <a href='https://wandb.ai/death-star/image-classification' target=\"_blank\">https://wandb.ai/death-star/image-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_211344-ke684kew/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ke684kew). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/learn/alexnet/wandb/run-20241011_211507-6wp77b8p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/death-star/image-classification/runs/6wp77b8p' target=\"_blank\">good-night-10</a></strong> to <a href='https://wandb.ai/death-star/image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/death-star/image-classification' target=\"_blank\">https://wandb.ai/death-star/image-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/death-star/image-classification/runs/6wp77b8p' target=\"_blank\">https://wandb.ai/death-star/image-classification/runs/6wp77b8p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/death-star/image-classification/runs/6wp77b8p?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb62cb94cd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 100\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = AlexNet(num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate,weight_decay=0.0005,momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "\n",
    "wandb.init(\n",
    "    project = \"image-classification\",\n",
    "    config = {\n",
    "        \"learning_rate\" : learning_rate,\n",
    "        \"architecture\" : \"AlexNet\",\n",
    "        \"dataset\" : \"CIFAR100\",\n",
    "        \"epochs\" : num_epochs\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [391/391], Loss: 4.1749\n",
      "Accuracy of the network on the 5000 validation images: 7.49 %\n",
      "Validation Loss: 4.1124\n",
      "Epoch [2/100], Step [391/391], Loss: 3.9280\n",
      "Accuracy of the network on the 5000 validation images: 13.93 %\n",
      "Validation Loss: 3.6262\n",
      "Epoch [3/100], Step [391/391], Loss: 3.2883\n",
      "Accuracy of the network on the 5000 validation images: 18.86 %\n",
      "Validation Loss: 3.3974\n",
      "Epoch [4/100], Step [391/391], Loss: 3.4857\n",
      "Accuracy of the network on the 5000 validation images: 21.62 %\n",
      "Validation Loss: 3.2389\n",
      "Epoch [5/100], Step [391/391], Loss: 2.9869\n",
      "Accuracy of the network on the 5000 validation images: 26.15 %\n",
      "Validation Loss: 3.0117\n",
      "Epoch [6/100], Step [391/391], Loss: 2.7560\n",
      "Accuracy of the network on the 5000 validation images: 29.74 %\n",
      "Validation Loss: 2.7829\n",
      "Epoch [7/100], Step [391/391], Loss: 2.5917\n",
      "Accuracy of the network on the 5000 validation images: 31.86 %\n",
      "Validation Loss: 2.6841\n",
      "Epoch [8/100], Step [391/391], Loss: 2.7199\n",
      "Accuracy of the network on the 5000 validation images: 34.97 %\n",
      "Validation Loss: 2.5429\n",
      "Epoch [9/100], Step [391/391], Loss: 2.4587\n",
      "Accuracy of the network on the 5000 validation images: 35.48 %\n",
      "Validation Loss: 2.5238\n",
      "Epoch [10/100], Step [391/391], Loss: 2.4690\n",
      "Accuracy of the network on the 5000 validation images: 39.19 %\n",
      "Validation Loss: 2.3395\n",
      "Epoch [11/100], Step [391/391], Loss: 2.2877\n",
      "Accuracy of the network on the 5000 validation images: 40.31 %\n",
      "Validation Loss: 2.3054\n",
      "Epoch [12/100], Step [391/391], Loss: 2.0591\n",
      "Accuracy of the network on the 5000 validation images: 41.75 %\n",
      "Validation Loss: 2.2473\n",
      "Epoch [13/100], Step [391/391], Loss: 2.0665\n",
      "Accuracy of the network on the 5000 validation images: 42.2 %\n",
      "Validation Loss: 2.2403\n",
      "Epoch [14/100], Step [391/391], Loss: 2.1712\n",
      "Accuracy of the network on the 5000 validation images: 45.25 %\n",
      "Validation Loss: 2.0729\n",
      "Epoch [15/100], Step [391/391], Loss: 1.9737\n",
      "Accuracy of the network on the 5000 validation images: 46.65 %\n",
      "Validation Loss: 1.9808\n",
      "Epoch [16/100], Step [391/391], Loss: 1.8206\n",
      "Accuracy of the network on the 5000 validation images: 47.34 %\n",
      "Validation Loss: 1.9798\n",
      "Epoch [17/100], Step [391/391], Loss: 1.7439\n",
      "Accuracy of the network on the 5000 validation images: 47.63 %\n",
      "Validation Loss: 1.9655\n",
      "Epoch [18/100], Step [391/391], Loss: 1.8642\n",
      "Accuracy of the network on the 5000 validation images: 47.79 %\n",
      "Validation Loss: 1.9617\n",
      "Epoch [19/100], Step [391/391], Loss: 2.2685\n",
      "Accuracy of the network on the 5000 validation images: 50.0 %\n",
      "Validation Loss: 1.8540\n",
      "Epoch [20/100], Step [391/391], Loss: 1.9188\n",
      "Accuracy of the network on the 5000 validation images: 50.93 %\n",
      "Validation Loss: 1.8313\n",
      "Epoch [21/100], Step [391/391], Loss: 1.7562\n",
      "Accuracy of the network on the 5000 validation images: 50.67 %\n",
      "Validation Loss: 1.8232\n",
      "Epoch [22/100], Step [391/391], Loss: 1.8612\n",
      "Accuracy of the network on the 5000 validation images: 51.88 %\n",
      "Validation Loss: 1.7883\n",
      "Epoch [23/100], Step [391/391], Loss: 1.9313\n",
      "Accuracy of the network on the 5000 validation images: 51.18 %\n",
      "Validation Loss: 1.8171\n",
      "Epoch [24/100], Step [391/391], Loss: 1.6600\n",
      "Accuracy of the network on the 5000 validation images: 49.37 %\n",
      "Validation Loss: 1.9633\n",
      "Epoch [25/100], Step [391/391], Loss: 2.3353\n",
      "Accuracy of the network on the 5000 validation images: 50.76 %\n",
      "Validation Loss: 1.8841\n",
      "Epoch [26/100], Step [391/391], Loss: 1.7258\n",
      "Accuracy of the network on the 5000 validation images: 52.97 %\n",
      "Validation Loss: 1.7410\n",
      "Epoch [27/100], Step [391/391], Loss: 1.6703\n",
      "Accuracy of the network on the 5000 validation images: 52.65 %\n",
      "Validation Loss: 1.7162\n",
      "Epoch [28/100], Step [391/391], Loss: 1.7764\n",
      "Accuracy of the network on the 5000 validation images: 54.52 %\n",
      "Validation Loss: 1.6499\n",
      "Epoch [29/100], Step [391/391], Loss: 1.4300\n",
      "Accuracy of the network on the 5000 validation images: 53.6 %\n",
      "Validation Loss: 1.7321\n",
      "Epoch [30/100], Step [391/391], Loss: 1.5209\n",
      "Accuracy of the network on the 5000 validation images: 53.95 %\n",
      "Validation Loss: 1.7066\n",
      "Epoch [31/100], Step [391/391], Loss: 1.3954\n",
      "Accuracy of the network on the 5000 validation images: 58.4 %\n",
      "Validation Loss: 1.4833\n",
      "Epoch [32/100], Step [391/391], Loss: 1.3598\n",
      "Accuracy of the network on the 5000 validation images: 58.48 %\n",
      "Validation Loss: 1.4924\n",
      "Epoch [33/100], Step [391/391], Loss: 1.2533\n",
      "Accuracy of the network on the 5000 validation images: 58.68 %\n",
      "Validation Loss: 1.4735\n",
      "Epoch [34/100], Step [391/391], Loss: 1.3819\n",
      "Accuracy of the network on the 5000 validation images: 59.0 %\n",
      "Validation Loss: 1.4840\n",
      "Epoch [35/100], Step [391/391], Loss: 1.0253\n",
      "Accuracy of the network on the 5000 validation images: 59.12 %\n",
      "Validation Loss: 1.4799\n",
      "Epoch [36/100], Step [391/391], Loss: 1.4187\n",
      "Accuracy of the network on the 5000 validation images: 59.23 %\n",
      "Validation Loss: 1.4761\n",
      "Epoch [37/100], Step [391/391], Loss: 1.4891\n",
      "Accuracy of the network on the 5000 validation images: 59.33 %\n",
      "Validation Loss: 1.4766\n",
      "Epoch [38/100], Step [391/391], Loss: 0.9634\n",
      "Accuracy of the network on the 5000 validation images: 59.12 %\n",
      "Validation Loss: 1.4825\n",
      "Epoch [39/100], Step [391/391], Loss: 1.2534\n",
      "Accuracy of the network on the 5000 validation images: 59.31 %\n",
      "Validation Loss: 1.4877\n",
      "Epoch [40/100], Step [391/391], Loss: 1.7935\n",
      "Accuracy of the network on the 5000 validation images: 59.51 %\n",
      "Validation Loss: 1.4713\n",
      "Epoch [41/100], Step [391/391], Loss: 1.3783\n",
      "Accuracy of the network on the 5000 validation images: 59.56 %\n",
      "Validation Loss: 1.4693\n",
      "Epoch [42/100], Step [391/391], Loss: 1.3888\n",
      "Accuracy of the network on the 5000 validation images: 59.52 %\n",
      "Validation Loss: 1.4767\n",
      "Epoch [43/100], Step [391/391], Loss: 1.1692\n",
      "Accuracy of the network on the 5000 validation images: 59.84 %\n",
      "Validation Loss: 1.4658\n",
      "Epoch [44/100], Step [391/391], Loss: 1.2981\n",
      "Accuracy of the network on the 5000 validation images: 59.5 %\n",
      "Validation Loss: 1.4650\n",
      "Epoch [45/100], Step [391/391], Loss: 1.1697\n",
      "Accuracy of the network on the 5000 validation images: 59.84 %\n",
      "Validation Loss: 1.4633\n",
      "Epoch [46/100], Step [391/391], Loss: 1.3155\n",
      "Accuracy of the network on the 5000 validation images: 59.59 %\n",
      "Validation Loss: 1.4666\n",
      "Epoch [47/100], Step [391/391], Loss: 1.5001\n",
      "Accuracy of the network on the 5000 validation images: 60.14 %\n",
      "Validation Loss: 1.4670\n",
      "Epoch [48/100], Step [391/391], Loss: 1.2325\n",
      "Accuracy of the network on the 5000 validation images: 59.38 %\n",
      "Validation Loss: 1.4717\n",
      "Epoch [49/100], Step [391/391], Loss: 1.1569\n",
      "Accuracy of the network on the 5000 validation images: 59.74 %\n",
      "Validation Loss: 1.4685\n",
      "Epoch [50/100], Step [391/391], Loss: 1.2981\n",
      "Accuracy of the network on the 5000 validation images: 60.27 %\n",
      "Validation Loss: 1.4586\n",
      "Epoch [51/100], Step [391/391], Loss: 1.3482\n",
      "Accuracy of the network on the 5000 validation images: 59.7 %\n",
      "Validation Loss: 1.4798\n",
      "Epoch [52/100], Step [391/391], Loss: 1.2982\n",
      "Accuracy of the network on the 5000 validation images: 59.75 %\n",
      "Validation Loss: 1.4843\n",
      "Epoch [53/100], Step [391/391], Loss: 1.0409\n",
      "Accuracy of the network on the 5000 validation images: 60.1 %\n",
      "Validation Loss: 1.4560\n",
      "Epoch [54/100], Step [391/391], Loss: 1.5157\n",
      "Accuracy of the network on the 5000 validation images: 60.15 %\n",
      "Validation Loss: 1.4589\n",
      "Epoch [55/100], Step [391/391], Loss: 1.3168\n",
      "Accuracy of the network on the 5000 validation images: 60.17 %\n",
      "Validation Loss: 1.4620\n",
      "Epoch [56/100], Step [391/391], Loss: 1.0181\n",
      "Accuracy of the network on the 5000 validation images: 59.97 %\n",
      "Validation Loss: 1.4698\n",
      "Epoch [57/100], Step [391/391], Loss: 1.1538\n",
      "Accuracy of the network on the 5000 validation images: 60.4 %\n",
      "Validation Loss: 1.4612\n",
      "Epoch [58/100], Step [391/391], Loss: 1.1148\n",
      "Accuracy of the network on the 5000 validation images: 60.41 %\n",
      "Validation Loss: 1.4562\n",
      "Epoch [59/100], Step [391/391], Loss: 1.1412\n",
      "Accuracy of the network on the 5000 validation images: 60.14 %\n",
      "Validation Loss: 1.4593\n",
      "Epoch [60/100], Step [391/391], Loss: 1.2029\n",
      "Accuracy of the network on the 5000 validation images: 59.99 %\n",
      "Validation Loss: 1.4773\n",
      "Epoch [61/100], Step [391/391], Loss: 1.1481\n",
      "Accuracy of the network on the 5000 validation images: 60.77 %\n",
      "Validation Loss: 1.4464\n",
      "Epoch [62/100], Step [391/391], Loss: 1.1213\n",
      "Accuracy of the network on the 5000 validation images: 60.71 %\n",
      "Validation Loss: 1.4433\n",
      "Epoch [63/100], Step [391/391], Loss: 1.4316\n",
      "Accuracy of the network on the 5000 validation images: 60.69 %\n",
      "Validation Loss: 1.4392\n",
      "Epoch [64/100], Step [391/391], Loss: 1.3011\n",
      "Accuracy of the network on the 5000 validation images: 60.72 %\n",
      "Validation Loss: 1.4418\n",
      "Epoch [65/100], Step [391/391], Loss: 1.1703\n",
      "Accuracy of the network on the 5000 validation images: 60.76 %\n",
      "Validation Loss: 1.4424\n",
      "Epoch [66/100], Step [391/391], Loss: 1.5074\n",
      "Accuracy of the network on the 5000 validation images: 60.5 %\n",
      "Validation Loss: 1.4462\n",
      "Epoch [67/100], Step [391/391], Loss: 1.3296\n",
      "Accuracy of the network on the 5000 validation images: 60.81 %\n",
      "Validation Loss: 1.4439\n",
      "Epoch [68/100], Step [391/391], Loss: 1.3205\n",
      "Accuracy of the network on the 5000 validation images: 60.96 %\n",
      "Validation Loss: 1.4398\n",
      "Epoch [69/100], Step [391/391], Loss: 1.3635\n",
      "Accuracy of the network on the 5000 validation images: 60.69 %\n",
      "Validation Loss: 1.4410\n",
      "Epoch [70/100], Step [391/391], Loss: 1.2775\n",
      "Accuracy of the network on the 5000 validation images: 60.76 %\n",
      "Validation Loss: 1.4434\n",
      "Epoch [71/100], Step [391/391], Loss: 1.2338\n",
      "Accuracy of the network on the 5000 validation images: 60.62 %\n",
      "Validation Loss: 1.4416\n",
      "Epoch [72/100], Step [391/391], Loss: 1.1042\n",
      "Accuracy of the network on the 5000 validation images: 60.97 %\n",
      "Validation Loss: 1.4422\n",
      "Epoch [73/100], Step [391/391], Loss: 1.3696\n",
      "Accuracy of the network on the 5000 validation images: 60.71 %\n",
      "Validation Loss: 1.4441\n",
      "Epoch [74/100], Step [391/391], Loss: 1.3208\n",
      "Accuracy of the network on the 5000 validation images: 60.83 %\n",
      "Validation Loss: 1.4403\n",
      "Epoch [75/100], Step [391/391], Loss: 1.0085\n",
      "Accuracy of the network on the 5000 validation images: 60.75 %\n",
      "Validation Loss: 1.4418\n",
      "Epoch [76/100], Step [391/391], Loss: 1.1032\n",
      "Accuracy of the network on the 5000 validation images: 60.76 %\n",
      "Validation Loss: 1.4437\n",
      "Epoch [77/100], Step [391/391], Loss: 1.3129\n",
      "Accuracy of the network on the 5000 validation images: 60.72 %\n",
      "Validation Loss: 1.4450\n",
      "Epoch [78/100], Step [391/391], Loss: 1.1973\n",
      "Accuracy of the network on the 5000 validation images: 60.85 %\n",
      "Validation Loss: 1.4425\n",
      "Epoch [79/100], Step [391/391], Loss: 1.4214\n",
      "Accuracy of the network on the 5000 validation images: 60.72 %\n",
      "Validation Loss: 1.4422\n",
      "Epoch [80/100], Step [391/391], Loss: 1.1750\n",
      "Accuracy of the network on the 5000 validation images: 60.79 %\n",
      "Validation Loss: 1.4452\n",
      "Epoch [81/100], Step [391/391], Loss: 1.3516\n",
      "Accuracy of the network on the 5000 validation images: 60.88 %\n",
      "Validation Loss: 1.4399\n",
      "Epoch [82/100], Step [391/391], Loss: 1.0143\n",
      "Accuracy of the network on the 5000 validation images: 60.91 %\n",
      "Validation Loss: 1.4407\n",
      "Epoch [83/100], Step [391/391], Loss: 1.3835\n",
      "Accuracy of the network on the 5000 validation images: 60.81 %\n",
      "Validation Loss: 1.4416\n",
      "Epoch [84/100], Step [391/391], Loss: 1.1925\n",
      "Accuracy of the network on the 5000 validation images: 60.8 %\n",
      "Validation Loss: 1.4433\n",
      "Epoch [85/100], Step [391/391], Loss: 1.1954\n",
      "Accuracy of the network on the 5000 validation images: 60.79 %\n",
      "Validation Loss: 1.4420\n",
      "Epoch [86/100], Step [391/391], Loss: 1.0256\n",
      "Accuracy of the network on the 5000 validation images: 60.8 %\n",
      "Validation Loss: 1.4410\n",
      "Epoch [87/100], Step [391/391], Loss: 1.1757\n",
      "Accuracy of the network on the 5000 validation images: 60.69 %\n",
      "Validation Loss: 1.4416\n",
      "Epoch [88/100], Step [391/391], Loss: 1.2263\n",
      "Accuracy of the network on the 5000 validation images: 60.8 %\n",
      "Validation Loss: 1.4457\n",
      "Epoch [89/100], Step [391/391], Loss: 1.3025\n",
      "Accuracy of the network on the 5000 validation images: 60.69 %\n",
      "Validation Loss: 1.4410\n",
      "Epoch [90/100], Step [391/391], Loss: 1.1197\n",
      "Accuracy of the network on the 5000 validation images: 60.75 %\n",
      "Validation Loss: 1.4432\n",
      "Epoch [91/100], Step [391/391], Loss: 0.9706\n",
      "Accuracy of the network on the 5000 validation images: 60.75 %\n",
      "Validation Loss: 1.4408\n",
      "Epoch [92/100], Step [391/391], Loss: 1.2324\n",
      "Accuracy of the network on the 5000 validation images: 60.83 %\n",
      "Validation Loss: 1.4411\n",
      "Epoch [93/100], Step [391/391], Loss: 1.3043\n",
      "Accuracy of the network on the 5000 validation images: 60.8 %\n",
      "Validation Loss: 1.4414\n",
      "Epoch [94/100], Step [391/391], Loss: 1.2677\n",
      "Accuracy of the network on the 5000 validation images: 60.94 %\n",
      "Validation Loss: 1.4407\n",
      "Epoch [95/100], Step [391/391], Loss: 1.1391\n",
      "Accuracy of the network on the 5000 validation images: 60.92 %\n",
      "Validation Loss: 1.4394\n",
      "Epoch [96/100], Step [391/391], Loss: 1.2492\n",
      "Accuracy of the network on the 5000 validation images: 60.83 %\n",
      "Validation Loss: 1.4393\n",
      "Epoch [97/100], Step [391/391], Loss: 1.3256\n",
      "Accuracy of the network on the 5000 validation images: 60.67 %\n",
      "Validation Loss: 1.4387\n",
      "Epoch [98/100], Step [391/391], Loss: 1.1847\n",
      "Accuracy of the network on the 5000 validation images: 60.93 %\n",
      "Validation Loss: 1.4411\n",
      "Epoch [99/100], Step [391/391], Loss: 1.0594\n",
      "Accuracy of the network on the 5000 validation images: 60.81 %\n",
      "Validation Loss: 1.4382\n",
      "Epoch [100/100], Step [391/391], Loss: 1.0018\n",
      "Accuracy of the network on the 5000 validation images: 60.86 %\n",
      "Validation Loss: 1.4411\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "          .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    wandb.log({\"train_loss\": loss.item()})\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "        val_loss /= len(valid_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, accuracy))\n",
    "        print('Validation Loss: {:.4f}'.format(val_loss))\n",
    "        wandb.log({\"val_loss\": val_loss, \"val_accuracy\": accuracy})\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 60.86%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images,labels in valid_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images,labels,outputs\n",
    "    print('Accuracy of the network on the {} test images: {}%'.format(10000,100 * correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the folder '/home/ubuntu/learn/alexnet' is 145.25 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size / (1024 * 1024)  # Convert bytes to megabytes\n",
    "\n",
    "folder_path = '/home/ubuntu/learn/alexnet'  # Replace with your folder path\n",
    "folder_size_mb = get_folder_size(folder_path)\n",
    "print(f\"Size of the folder '{folder_path}' is {folder_size_mb:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
