{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf4f7ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"distilbert-base-uncased\",\n",
    "    \"roberta-base\",\n",
    "    \"microsoft/deberta-v3-base\",\n",
    "    \"bert-large-uncased\",\n",
    "    \"roberta-large\",\n",
    "    \"microsoft/deberta-v3-large\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6314228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "train_dir = \"./data/train\"\n",
    "\n",
    "ref_df = pd.read_csv(\"./data/train.csv\")\n",
    "train_df = pd.DataFrame(columns=[\"text\", \"labels\"])\n",
    "\n",
    "for _, row in ref_df.iterrows():\n",
    "    id = row[\"id\"]\n",
    "    real_text_id = row[\"real_text_id\"]\n",
    "\n",
    "    file_prefix = f\"article_{id:04d}\"\n",
    "\n",
    "    file_path_dir = os.path.join(train_dir, file_prefix)\n",
    "\n",
    "    file_1_path = os.path.join(file_path_dir, \"file_1.txt\")\n",
    "    file_2_path = os.path.join(file_path_dir, \"file_2.txt\")\n",
    "\n",
    "    with open(file_1_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        file_1_text = f.read().strip()\n",
    "    with open(file_2_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        file_2_text = f.read().strip()\n",
    "\n",
    "    if real_text_id == 1:\n",
    "        train_df = pd.concat(\n",
    "            [train_df, pd.DataFrame({\"text\": [file_1_text], \"labels\": [0]})],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        train_df = pd.concat(\n",
    "            [train_df, pd.DataFrame({\"text\": [file_2_text], \"labels\": [1]})],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "    else:\n",
    "        train_df = pd.concat(\n",
    "            [train_df, pd.DataFrame({\"text\": [file_1_text], \"labels\": [1]})],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        train_df = pd.concat(\n",
    "            [train_df, pd.DataFrame({\"text\": [file_2_text], \"labels\": [0]})],\n",
    "            ignore_index=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbfe5853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_model_and_tokenizer(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = F.softmax(torch.tensor(logits), dim=1).detach().cpu().numpy()\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "\n",
    "    probs_class1 = probs[:, 1]\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"binary\"\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    auc = roc_auc_score(labels, probs_class1)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"aucroc\": auc,\n",
    "    }\n",
    "\n",
    "def run_test(idx,model,tokenizer):\n",
    "\n",
    "    test_df = pd.DataFrame(columns=[\"id\", \"real_text_id\"])\n",
    "    test_dir = \"./data/test\"\n",
    "\n",
    "    for i in range(len(os.listdir(test_dir))):\n",
    "        file_prefix = f\"article_{i:04d}\"\n",
    "        file_path_dir = os.path.join(test_dir, file_prefix)\n",
    "\n",
    "        file_1_path = os.path.join(file_path_dir, \"file_1.txt\")\n",
    "        file_2_path = os.path.join(file_path_dir, \"file_2.txt\")\n",
    "\n",
    "        with open(file_1_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            file_1_text = f.read().strip()\n",
    "        with open(file_2_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            file_2_text = f.read().strip()\n",
    "\n",
    "        inputs_1 = tokenizer(\n",
    "            file_1_text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\"\n",
    "        ).to(\"cuda\")\n",
    "        inputs_2 = tokenizer(\n",
    "            file_2_text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\"\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        inputs_1.pop(\"token_type_ids\", None)\n",
    "        inputs_2.pop(\"token_type_ids\", None)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs_1 = model(**inputs_1)\n",
    "            outputs_2 = model(**inputs_2)\n",
    "\n",
    "        logits_1 = outputs_1[\"logits\"]\n",
    "        logits_2 = outputs_2[\"logits\"]\n",
    "\n",
    "        probs_1 = F.softmax(logits_1, dim=1).detach().cpu().numpy()\n",
    "        probs_2 = F.softmax(logits_2, dim=1).detach().cpu().numpy()\n",
    "\n",
    "        human_prob_file1 = probs_1[0][0]\n",
    "        human_prob_file2 = probs_2[0][0]\n",
    "\n",
    "        real_text_id = 1 if human_prob_file1 > human_prob_file2 else 2\n",
    "\n",
    "        test_df = pd.concat(\n",
    "            [\n",
    "                test_df,\n",
    "                pd.DataFrame({\"id\": [i], \"human_prob_file1\": [human_prob_file1], \"human_prob_file2\": [human_prob_file2], \"real_text_id\": [real_text_id]}),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        test_df.to_csv(f\"submission_{idx}.csv\")\n",
    "\n",
    "def train_model_and_test(idx,model_name):\n",
    "    tokenizer, model = prepare_model_and_tokenizer(model_name)\n",
    "    dataset = Dataset.from_pandas(train_df)\n",
    "    data = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "    train_dataset = data[\"train\"]\n",
    "    val_dataset = data[\"test\"]\n",
    "\n",
    "    def preprocess(batch):\n",
    "        return tokenizer(\n",
    "            batch[\"text\"],\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "        )\n",
    "\n",
    "    train_dataset = train_dataset.map(preprocess, batched=True)\n",
    "    val_dataset = val_dataset.map(preprocess, batched=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./{model_name}-kaggle\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        eval_strategy=\"epoch\",\n",
    "        eval_steps=None,\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        learning_rate=3e-5,\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    run_test(idx,model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e51dd4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264acee54d164d76a904f21fa683c97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256b079109df42bf891d2e06ba4ede53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [129/129 00:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>0.550647</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.716975</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.325900</td>\n",
       "      <td>0.789641</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69c330b5e58444ca75101bd12b9735c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7291ff5f624de694b41284b29455a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [129/129 00:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.538900</td>\n",
       "      <td>0.510267</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.475600</td>\n",
       "      <td>0.844009</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.829545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>1.208025</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/idm/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9ab7588f7047bd88e9a265205466ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff6e2adcf2b46b5927bda97b3aa7134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [129/129 01:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.537600</td>\n",
       "      <td>0.530011</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.806818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>0.556788</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.630077</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.784091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7071c6c28df4a779b635c7d77720717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb456f672da4527858fc9a3032f8269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [129/129 02:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.817163</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>0.821242</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.795455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.376500</td>\n",
       "      <td>0.914039</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ad5c0c78944bf38a45f77dc8160681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfef6ed8179419dab00adf7153be825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [129/129 03:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.507300</td>\n",
       "      <td>0.789666</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.508800</td>\n",
       "      <td>0.755896</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.806818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>1.643301</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.840909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/idm/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c4fa9ccc9141ecac7c92b825711843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb25bfb13ce42a386c196692e75eb2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [129/129 04:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.428400</td>\n",
       "      <td>0.518875</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.715909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>1.068425</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.670455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.429100</td>\n",
       "      <td>1.345046</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx,model_name in enumerate(model_names):\n",
    "    train_model_and_test(idx,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c857da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting complete. Saved to final_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import glob\n",
    "\n",
    "csv_files = sorted(glob.glob(\"submission_*.csv\"))\n",
    "\n",
    "dfs = [pd.read_csv(file) for file in csv_files]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "final_df[\"id\"] = dfs[0][\"id\"]\n",
    "\n",
    "def majority_vote(values):\n",
    "    return Counter(values).most_common(1)[0][0]\n",
    "\n",
    "\n",
    "predictions = pd.concat([df[\"real_text_id\"] for df in dfs], axis=1)\n",
    "\n",
    "final_df[\"real_text_id\"] = predictions.apply(majority_vote, axis=1)\n",
    "\n",
    "final_df.to_csv(\"final_submission.csv\", index=False)\n",
    "\n",
    "print(\"Voting complete. Saved to final_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c14975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble complete! Final file saved as ensemble_submission.csv\n"
     ]
    }
   ],
   "source": [
    "csv_files = sorted(glob.glob(\"submission_*.csv\"))\n",
    "dfs = [pd.read_csv(file) for file in csv_files]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "final_df[\"id\"] = dfs[0][\"id\"]\n",
    "\n",
    "prob_file1 = pd.concat([df[\"human_prob_file1\"] for df in dfs], axis=1).mean(axis=1)\n",
    "prob_file2 = pd.concat([df[\"human_prob_file2\"] for df in dfs], axis=1).mean(axis=1)\n",
    "\n",
    "final_df[\"human_prob_file1_avg\"] = prob_file1\n",
    "final_df[\"human_prob_file2_avg\"] = prob_file2\n",
    "final_df[\"real_text_id\"] = (prob_file1 > prob_file2).astype(int) + 1  \n",
    "\n",
    "final_df[[\"id\", \"real_text_id\"]].to_csv(\"ensemble_submission.csv\", index=False)\n",
    "\n",
    "print(\"Ensemble complete! Final file saved as ensemble_submission.csv\")\n",
    "\n",
    "# worse than voting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
